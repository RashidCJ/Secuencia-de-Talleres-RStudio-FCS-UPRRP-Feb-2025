---
title: 'CACCS: Secuencia de taller de RStudio -- Parte 2'
author: "Rashid C.J. Marcano Rivera"
date: "18 de oct.·µâ de 2024"
output:
  html_document:
    theme: cerulean
    toc: TRUE
    toc_float: TRUE
    number_sections: TRUE
editor_options: 
  markdown: 
    wrap: 90
---

**Inferencia estad√≠stica**

Este taller est√° basado en elementos y ejemplos del libro de Rafael
Irizarry, [aqu√≠](https://rafalab.dfci.harvard.edu/dslibro), as√≠ como
pedazos del curso de la Universidad de la Rep√∫blica, en Uruguay,
disponible en esta p√°gina de [RPubs de
RStudio](https://rpubs.com/lercy/930251) y este repaso sobre modelos
longitudinales por Alessio Crippa tambi√©n en [RPubs de
RStudio](https://rpubs.com/alecri/review_longitudinal).

*Si a√∫n no has instalado R, est√° [aqu√≠](http://cran.us.r-project.org/).
Acto seguido, [baja
RStudio](https://posit.co/download/rstudio-desktop/). Puedes tambi√©n ir
a la nube [en Posit Cloud](https://posit.cloud/).*

# Recapitulando

La vez anterior, tomamos un recorrido a trav√©s de distintos tipos de
visualizaciones. En efecto, una buena visualizaci√≥n puede demostrar
bastante sobre factores en nuestros estudios. Por ejemplo

```{r Cargando datos de Wooldridge}
library(wooldridge)

data(wage1)
head(wage1)

```

¬øQu√© aprendemos de ver estos datos as√≠? ¬øPodemos r√°pidamente determinar
a si a√±os de educaci√≥n se traducen a mayores ingresos? ¬øPodemos
determinar si afecta en algo la relaci√≥n marital? Para muchos humanos,
es dif√≠cil extraer informaci√≥n con meramente mirar a n√∫meros sin
contexto adicional. Pero podr√≠amos ver algo en este gr√°fico

![Meta 1: datos de ingreso.](RelacioÃÅn.png)

Vivimos en una era de creciente disponibilidad de conjuntos de datos
informativos y de herramientas de software, con lo cual el uso de
visualizaciones ha aumentado en diversos espacios: acad√©micos,
gubernamentales, organizaciones sociales, prensa, e industrias varias.

En R, un programa estad√≠stico dise√±ado para la ejecuci√≥n de distintos
formatos de estad√≠sticas, tenemos un sinn√∫mero de opciones para
distintos tipos de complejidades en datos y an√°lisis.

Esta fue una secuencia de tres semanas, y en esta lecci√≥n continuamos de
lo aprendido en el pasado; retomamos problemas que visualizamos aunque
no fuera satisfactorio, para analizarlos con an√°lisis estad√≠sticos y
visualizaciones relativas a la inferencia estad√≠stica. Aprenderemos hoy:

1.  Varias operaciones estad√≠sticas,

2.  estad√≠stica inferencial, en sus varias versiones para modelos
    simples, lineales, jer√°rquicos y longitudinales.

3.  gr√°ficos que ayuden a entender y diagnosticar los modelos
    estad√≠sticos que usaremos

# Modelos estad√≠sticos

Quer√≠amos entender la vez anterior la relaci√≥n de ingreso con otras
variables. Para cargar los datos escribiremos

```{r}
library(wooldridge)
base <- wage1
#View(base) 
names(base)
?wage1
```

Las variables que utilizaremos son las siguientes:

-   wage: salario promedio por hora.

-   educ: a√±os de educaci√≥n.

-   exper: a√±os de experiencia potencial.

-   tenure: a√±os con el empleador actual (antig√ºedad).

-   nonwhite: es igual a 1 si la persona no es blanca, 0 si no.

-   female: es igual a 1 si la persona es mujer, 0 si no

-   married: es igual a 1 si la persona es casada, 0 si no.

En primer lugar queremos cambiar el nombre de la variable que est√° en la
posici√≥n 4:

```{r}
names(base)[4] <- "antig√ºedad"
names(base)[24] <- "antig√ºedadcuad"

```

Por ahora lo que nos interesaba es un subconjunto de variables, todas de
la 1 a la 7 (la 4.¬™ ha quedado como antig√ºedad), la 22 (log. de
salario), la 23 (experiencia al cuadrado) y la 24 (la antig√ºedad al
cuadrado).

```{r, Selecci√≥n de variables}
base1 <- base[,c(1: 7, 22:24)] 
```

Veremos ahora las primeras filas

```{r}
head(base1, n = 10)
```

Tambi√©n podr√≠amos llamarlos con el nombre de variable

```{r, subconjuntos b√°sicos}
datos1 <- base[,c("wage","educ","exper", "antig√ºedad" )] 

head(datos1, n = 5)
```

o como cubrimos al tocar `tidyverse`, la funci√≥n `select()`

```{r, Select()}
library(tidyverse)
datos2 <- base %>% select("wage", "educ", "exper", "antig√ºedad")
head(datos2, n=7)


```

Si solamente quisi√©ramos los datos de los casados podr√≠amos usar la
funci√≥n de filtrado

```{r, S√≥lo casados}
datos3 <- base %>% 
  select("wage", "educ", "exper", "antig√ºedad", "married") %>% 
  filter(married == 1)
```

# Correlaciones

Para investigar si hay correlaci√≥n entre alguna de las variables se
puede realizar un gr√°fico en el que se presenta la dispersi√≥n para cada
par de variables.

```{r, Correlaciones}
plot(datos2)
```

Y tambi√©n calcular la matriz de correlaciones de las variables que
figuran en *datos2*.

```{r, Correlaciones 2}
cor(datos2)
```

Notamos que existe una correlaci√≥n positiva entre el salario y la
educaci√≥n (0.4059)

Crearemos el diagrama de dispersi√≥n entre salario y educaci√≥n utilizando
las funciones de la librer√≠a ggplot2.

```{r}
ggplot(datos2, aes(x = educ, y = wage)) + 
  geom_point() + theme_light() +
  ggtitle("Relaci√≥n entre salario y educaci√≥n")
```

Se acordar√°n que la vez anterior a√±adimos complicaciones como un nivel
adicional en la capa de color:

```{r}
wage1 |> 
  mutate(marital = factor(married, levels = c(0, 1), labels = c("Soltero", "Casado"))) |> 
  ggplot(aes(educ, wage)) +  geom_point(aes(colour = marital), size = 3)+
  labs(title="Relaci√≥n entre educaci√≥n y salario",
       x = "Educaci√≥n", 
       y = "Salario",
       color = "Estado marital",
       caption = "Datos de Wooldridge, usado en p√°gs. como 7, 17, 33-34, 37, 76,...")

```

Esto lo exploraremos m√°s al entrar en modelos de regresi√≥n lineal
m√∫ltiple. Empezaremos por el modelo de regresi√≥n lineal simple.

# Modelo de regresi√≥n lineal simple

Estimamos un modelo de regresi√≥n lineal simple, con el m√©todo m√≠nimos
cuadrados ordinarios (en adelante MCO, OLS en ingl√©s) que explique los
salarios en funci√≥n de los a√±os de educaci√≥n de las personas. En R esto
se hace con la funci√≥n `lm()`:

```{r, MCO}
mod1 <- lm(wage ~ educ, data=datos2)
summary(mod1) # para imprimir la salida
```

¬øC√≥mo se lee esta salida? La primera l√≠nea indica la f√≥rmula que se
utiliz√≥. La segunda es sobre la distribuci√≥n de residuos las diferencias
entre los valores observados de `wage` y los valores predichos por el
modelo. La mediana cercana a cero indica que los residuos est√°n
centrados alrededor de cero. El rango de los residuos sugiere que hay
algunos valores at√≠picos, especialmente en el extremo m√°ximo (16.6085),
lo que podr√≠a indicar la presencia de salarios excepcionalmente altos no
explicados completamente por el modelo.

Vamos a los coeficientes: la columna de `Estimate` tiene el valor
estimado de coeficientes, mientras que la columna de `Std. Error` nos da
la desviaci√≥n est√°ndar estimada de la estimaci√≥n del coeficiente. El
puntaje t reporta la distancia en distribuci√≥n t de la muestra,
vis-√†-vis otras presunciones (de nulo efecto), con la √∫ltima columna
proveyendo el valor p, probabilidad asociada al puntaje t.

El intercepto de -0.9 representa el salario promedio cuando los a√±os de
educaci√≥n son cero. Sin embargo, en la pr√°ctica, es poco com√∫n que una
persona tenga cero a√±os de educaci√≥n, por lo que este valor tiene una
interpretaci√≥n limitada. El valor p es algo elevado, lo que indica que
no podr√≠amos afirmar con certeza su diferencia de cero. El coeficiente
en educaci√≥n indica que cada a√±o en educaci√≥n (una unidad adicional) se
traducir√≠a en un aumento de 0.54136 unidades en salario (si son pesos,
pues 54 chavos). El valor p es bajo (o el puntaje t es elevado, distante
a 2), lo que indica con cierta certeza que el estimado no es cero. Vemos
esto acompa√±ado con asteriscos, que indican el nivel de significancia,
atado al valor seleccionado $\alpha$.

El modelo luego contin√∫a reportando otros diagn√≥sticos generales:\
- Residual standard error (Error est√°ndar de los residuos): m√°s o menos 3.378

-- Indica la variabilidad promedio de los residuos; en otras palabras,
mide la precisi√≥n del modelo. Esto sugiere que las predicciones individuales del salario pueden variar en promedio ¬±3.378 unidades del valor real.


- Degrees of freedom (Grados de libertad): 524
-- Calculado como el n√∫mero de observaciones menos el n√∫mero de par√°metros estimados (n - k - 1).

- El coeficiente de determinaci√≥n (R cuadrado) nos da 0.1648, que indica que el 16.48% de la variabilidad se explica con el modelo. El R cuadrado ajustado es similar. Este penaliza la inclusi√≥n de t√©rminos adicionales. 

- El estad√≠stico F y el valor p global eval√∫a la hip√≥tesis nula de que todos los coeficientes sean iguales a cero.

y el an√°lisis de varianzas se calcula con la funci√≥n `anova()`:

```{r}
anova(mod1) # para imprimir el an√°lisis de varianzas
```

Este an√°lisis descompone la variabilidad total de la variable dependiente (`wage` en este caso) en componentes atribuibles al modelo y a los residuos. Te permite evaluar la significancia global del modelo y del predictor incluido. 

El objeto creado a trav√©s de la funci√≥n `lm()`, de clase lm, tiene en s√≠
doce objetos:

```{r, adentro del modelo}
names(mod1)

```

Se puede acceder a ellos como a las variables dentro de un objeto,
utilizando el operador `$` entre el objeto y el elemento. Por ejemplo,
para extraer los coeficientes estimados se escribe lo siguiente:

```{r, coeficientes}
mod1$coefficients
```

Para consultar la estimaci√≥n de un coeficiente de regresi√≥n se utilizan
par√©ntesis rectos y se indica la ubicaci√≥n del mismo dentro de la salida
del `summary()`. Alfa hat (es decir, el alfa gorro o el alfa estimado)
se saca:

```{r}
ahat <- coef(summary(mod1))[1,1]
ahat
```

Y el beta hat, beta gorro o beta estimado es:

```{r}
bhat <- coef(summary(mod1))[2,1]
bhat
```

Podemos sacar los pr√≥ximos pasos:

```{r}
coeficientes <- mod1$coefficients
ygorro <- mod1$fitted.values
resid <- mod1$residuals
```

Por √∫ltimo, podemos agregar al conjunto de datos original las
predicciones, en este caso salario estimado, que se obtienen con la
funci√≥n `predict()`.

```{r}
datos2$predicciones <- predict(mod1) 
head(datos2, 5)
```

El gr√°fico de dispersi√≥n puede establecerse

```{r}
ggplot(datos2, aes(x = educ, y = wage)) + 
  geom_point() +
  geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, col = 'dodgerblue1') +
  theme_light() +
  ggtitle("Relaci√≥n entre salario y educaci√≥n")
```

Si quisi√©ramos un gr√°fico de dispersi√≥n interactivo, podemos usar
plotly. As√≠, posicion√°ndose encima de cada observaci√≥n, se ven los
valores de (x, y) para cada uno de los individuos. Para construir dicho
gr√°fico se necesita la funci√≥n ggplotly() del paquete plotly.

```{r}
library(plotly)

ggplotly(data = datos2, x = ~ educ, y = ~ wage)
```

En la evaluaci√≥n de un modelo lineal tenemos que entender que tiene una
serie de presunciones.

1.  **Linealidad**: La relaci√≥n entre las variables dependiente e
    independiente debe ser lineal, es decir, puede ser representada como
    una l√≠nea recta en el plano de coordenadas.

2.  **Independencia de los errores**: Los residuos o errores (la
    diferencia entre los valores observados y los valores predichos por
    el modelo) deben ser independientes entre s√≠. Esto significa que no
    debe haber correlaci√≥n entre los errores.

3.  **Homoscedasticidad**: La varianza de los errores debe ser constante
    a lo largo de todos los valores de las variables independientes.
    Esto implica que la dispersi√≥n de los residuos debe ser la misma a
    lo largo del rango de valores de la variable independiente.

4.  **Normalidad de los errores**: Los errores deben seguir una
    distribuci√≥n normal. Este supuesto es importante para la realizaci√≥n
    de pruebas de hip√≥tesis y la construcci√≥n de intervalos de
    confianza.

5.  **No multicolinealidad**: Las variables independientes no deben
    estar altamente correlacionadas entre s√≠. La multicolinealidad puede
    dificultar la estimaci√≥n precisa de los coeficientes de regresi√≥n.

De violarse estas presunciones, el modelo estar√° sesgado y sus
resultados no ser√°n del todo fiables.

Podremos revisar algunos de estos a trav√©s de varios m√©todos: Podemos
por ejemplo calcular los residuos del modelo simple y los agregamos al
conjunto de datos (*datos2*) de la siguiente forma:

```{r}
datos2$residuos <- datos2$wage - datos2$predicciones
head(datos2, 5)
```

Comparamos los residuos calculados manualmente con los que nos dio el
modelo. En este caso a√±adimos la complicaci√≥n al modelo de los valores
estimados de y, $\hat{y}_i$, en rojo y muestro los residuos $\hat{u}_i$:

```{r}
resid <- mod1$residuals
datos2$resid <- resid
datos2$verif <- datos2$residuos - datos2$resid

ggplot(datos2, aes(x = educ, y = wage)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +
  geom_segment(aes(xend = educ, yend = predicciones), col = 'red', lty = 'dashed') +
  geom_point() +
  geom_point(aes(y = predicciones), col = 'red') +
  theme_light()
```

Podemos realizar un gr√°fico de dispersi√≥n para inspeccionar de forma
gr√°fica los residuos.

```{r}
plot(datos2$residuos)
```

```{r}
library(e1071)  # para la funci√≥n skewness
par(mfrow = c(1, 2))  # divide el √°rea de gr√°ficos en 2 columnas

plot(density(datos2$wage), main = "Gr√°fico de densisdad: salario", ylab = "Frecuencia", sub = paste("Asimetr√≠a:", round(e1071::skewness(datos2$wage), 2)))  # density para 'salario'

polygon(density(datos2$wage), col = "red")

plot(density(datos2$residuos), main = "Gr√°fico de densisdad: residuos", ylab = "Frecuencia", sub = paste("Asimetr√≠a:", round(e1071::skewness(datos2$residuos), 2)))  # density para los 'residuos'

polygon(density(datos2$residuos), col = "red")
```

A partir de los datos con los que se viene trabajando, vamos a generar
la predicci√≥n puntual y el intervalo de confianza para una educaci√≥n de
10 a√±os.

Primero, calculamos el salario esperado para una persona con la
educaci√≥n promedio: $\frac{y}{x}=\bar{x}$.

```{r}
mean(datos2$educ)
sal_pred <- 0.90485 + 0.054136 * 12.56
sal_pred
```

En segundo lugar, calculamos el intervalo de confianza para una persona
con la educaci√≥n promedio ($ùë•=12.56$) El argumento
`interval = prediction` devuelve el valor para la predicci√≥n puntual.

```{r}
nuevo <- data.frame(educ = 12.56)
future_y <- predict(object = mod1, newdata = nuevo, interval = "prediction", level = 0.95)
```

Luego, generamos el intervalo de confianza para $ùê∏(ùë¶/ùë•)$. en este caso,
debemos cambiar el argumento a `interval = "confidence"`.

```{r}
future_esp_y <- predict(object = mod1, newdata = nuevo, interval = "confidence", level = 0.95)
future_esp_y <- as.data.frame(future_esp_y)

IC_inf_esp_y <- future_esp_y$lwr
IC_sup_esp_y <- future_esp_y$upr
```

Agregando los pedazos

```{r}
nuevos_datos <- cbind(datos2, future_y, IC_inf_esp_y, IC_sup_esp_y)
```

Finalmente, generamos los gr√°ficos correspondientes con los intervalos
de confianza para la predicci√≥n puntual (`IC_y`) y para el valor
esperado (`IC_esp_y`) con el siguiente c√≥digo:

```{r}
IC_y <- ggplot(nuevos_datos, aes(x = educ, y = wage)) +
  geom_point() +
  geom_line(aes(y = lwr), color = "red", linetype = "dashed") +
  geom_line(aes(y = upr), color = "red", linetype = "dashed") +
  geom_smooth(method = lm, formula = y ~ x, se = TRUE, level = 0.95, col = 'blue', fill = 'pink2') +
  theme_light() + 
  ggtitle("Predicci√≥n de y al 95%")

IC_esp_y <- ggplot(nuevos_datos, aes(x = educ, y = wage)) +
  geom_point() +
  geom_line(aes(y = IC_inf_esp_y), color = "blue", linetype = "dashed") +
  geom_line(aes(y = IC_inf_esp_y), color = "blue", linetype = "dashed") +
  geom_smooth(method = lm, formula = y~x, se = TRUE, level = 0.95, col = 'blue', fill = 'pink2') +
  theme_light() + 
  ggtitle("Predicci√≥n de E(y/x) al 95%")
```

Imprimimos los gr√°ficos uno al lado del otro, para poder compararlos
mejor. ¬øCu√°l de los dos tiene mayor amplitud?

```{r}
library(gridExtra)

grid.arrange(IC_esp_y, IC_y, ncol = 2, nrow = 1)
```

Veamos, a trav√©s de la comparaci√≥n de dos gr√°ficos el impacto que tiene
el nivel de confianza en la amplitud de los intervalos. Para ello,
tendremos que descargar e instalar algunas librer√≠as. Se presenta
primero el c√≥digo y luego los gr√°ficos obtenidos.

```{r}
library(jtools)
library(ggstance)
library(broom.mixed)

a <- plot_summs(mod1, escala = TRUE, plot.distributions = TRUE, inner_ci_level = .90)
b <- plot_summs(mod1, escala = TRUE, plot.distributions = TRUE, inner_ci_level = .7) 

grid.arrange(a, b, ncol = 1, nrow = 2)
```

## Regresi√≥n m√∫ltiple

Digamos que queremos evaluar la relaci√≥n de varias variables con la
dependiente. Podemos calcular las correlaciones de los pares de
variables, indicando que queremos trabajar con 3 decimales:

```{r}
round(cor(base1, method = "pearson"), 3)

```

Podemos analizar varias variables en un grafo interactivo

```{r}
library(ggplot2)
library(plotly)
attach(base1)
plot_ly(x = educ, y = antig√ºedad, z = wage, type = "scatter3d", color = wage) %>% 
  layout(scene = list(xaxis = list(title = 'educaci√≥n (en a√±os)'),
                      yaxis = list(title = 'antig√ºedad (en a√±os)'),
                      zaxis = list(title = 'Salario (en USD/h)')))
```

```{r}
library(scatterplot3d)
graf <- scatterplot3d(x = educ, y = antig√ºedad, z = wage, pch = 16, 
              cex.lab = 1, highlight.3d = TRUE, type = "h", 
              xlab = 'A√±os de educaci√≥n',
              ylab = 'Antig√ºedad (a√±os)', 
              zlab = 'Salario (USD/h)')
```

Estimar el modelo m√∫ltiple:

```{r}
mod2 <- lm(wage ~ educ + antig√ºedad, data = base1)
summary(mod2)
```

```{r}
graf <-  scatterplot3d(x = educ, y = antig√ºedad, z = wage, pch = 16, 
                     cex.lab = 1, highlight.3d = TRUE, type = "h", 
                     xlab = 'A√±os de educaci√≥n',
                     ylab = 'Experiencia (a√±os)', 
                     zlab = 'Salario (USD/h)')

graf$plane3d(mod2, lty.box = "solid", col = 'mediumblue')
```

Analizando varianza del modelo

```{r}
anova(mod2)
```

## An√°lisis de la bondad del modelo

Podemos evaluar el modelo gr√°ficamente con la funci√≥n `plot()`:

```{r}
plot(mod2)
```

Notamos que el modelo tiene sus problemas, violentando varios de los
principios se√±alados antes.

```{r}
library(e1071)  # librer√≠a necesaria para utilizar la funci√≥n skewness()

plot(density(mod2$residuals), 
     main = "Gr√°fico de densidad de residuos", ylab = "Frecuencia", 
     sub = paste("Asimetr√≠a:", round(e1071::skewness(mod1$residuals), 2)))  

polygon(density(mod2$residuals), col = "red")
```

Por ejemplo, estos residuos distan de ser normales. Las cuantilas de los
residuos distan de la normalidad esperada.

```{r, Prueba Shapiro}
shapiro.test(mod2$residuals)
```

La hip√≥tesis nula de la prueba de Shapiro-Wilk es que estamos ante
normalidad en los errores. Esto confirma lo sugerido por el an√°lisis
gr√°fico precedente.

En los siguientes gr√°ficos se muestran los residuos contra cada uno de
los regresores, los cuales se realizan con el siguiente c√≥digo:

```{r}
plot1 <- ggplot(data = base1, aes(educ, mod1$residuals)) +
  geom_point() + 
  geom_smooth(color = "firebrick") + 
  geom_hline(yintercept = 0) +
  theme_bw()

plot2 <- ggplot(data = base1, aes(antig√ºedad, mod1$residuals)) +
  geom_point() + 
  geom_smooth(color = "firebrick") + 
  geom_hline(yintercept = 0) +
  theme_bw()

grid.arrange(plot1, plot2)
```

El an√°lisis gr√°fico indica problemas de heteroscedasticidad y de
correlaci√≥n entre los residuos y el nivel de los regresores.

Una manera resumida de verlo es graficando los residuos contra los
valores ajustados de $y$, que es una combinaci√≥n lineal de los
regresores que estamos considerando.

```{r}
ggplot(data = base1, aes(mod1$fitted.values, mod1$residuals)) +
  geom_point() +
  geom_smooth(color = "firebrick", se = FALSE) +
  geom_hline(yintercept = 0) +
  theme_bw()
```

Los problemas se√±alados antes se ven igual.

```{r}
mod3<-update(mod2,wage~educ+antig√ºedad+married)
summary(mod3)

```

Veamos los coeficientes

```{r}
library(modelsummary)
modelplot(mod3, coef_omit="Intercept", color="blue", size=1) +
  labs(title="Coeficientes crudos del modelo 3")
```

En este caso algunos de estos quiz√°s no sean visualmente buenos para
comparar: usan escalas distintas: uno es un efecto neto del ser o no
casado, mientras otros usan escalas num√©ricas significativas.
Estandaricemos esto para fin de entender el efecto real.

```{r}
base1_estandarizado <- base1 %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), scale))

mod3.1<-update(mod3,data=base1_estandarizado)

modelplot(mod3.1, coef_omit="Intercept", color="blue", size=1) +
  labs(title="Coeficientes estandarizados del modelo 3")
```

¬øSer√° igual de problem√°tico el modelo? Podemos Al ejecutar plot(modelo)
en R, se generan cuatro gr√°ficos diagn√≥sticos que ayudan a evaluar la
adecuaci√≥n y los supuestos del modelo ajustado. A continuaci√≥n, los
veremos, y luego describo c√≥mo interpretarlos:

```{r}
plot(mod3)
```

1.  Residuos vs Ajustados (Residuals vs Fitted):

    ‚Ä¢ Qu√© muestra: Este gr√°fico representa los residuos estandarizados
    en funci√≥n de los valores ajustados por el modelo. ‚Ä¢ Interpretaci√≥n:
    Sirve para detectar patrones no lineales y evaluar la homogeneidad
    de la varianza (homocedasticidad). Si los puntos se distribuyen
    aleatoriamente alrededor de la l√≠nea horizontal (residuo = 0) sin
    formar patrones, indica que el modelo es adecuado. Patrones
    sistem√°ticos o formas espec√≠ficas (como una curva) sugieren que el
    modelo no captura adecuadamente la relaci√≥n entre las variables, o
    que existe heterocedasticidad.

2.  Gr√°fico Q-Q Normal (Normal Q-Q Plot):

    ‚Ä¢ Qu√© muestra: Compara la distribuci√≥n de los residuos
    estandarizados con una distribuci√≥n normal te√≥rica. ‚Ä¢
    Interpretaci√≥n: Eval√∫a la normalidad de los residuos, un supuesto
    clave en modelos lineales. Si los puntos siguen aproximadamente una
    l√≠nea recta, los residuos se distribuyen normalmente. Desviaciones
    significativas de la l√≠nea recta indican que los residuos no son
    normales, lo que puede afectar la validez de los intervalos de
    confianza y pruebas de hip√≥tesis.

3.  Escala-Ubicaci√≥n (Scale-Location Plot):

    ‚Ä¢ Qu√© muestra: Grafica la ra√≠z cuadrada de los residuos
    estandarizados (sqrt(\|Residuos estandarizados\|)) frente a los
    valores ajustados. ‚Ä¢ Interpretaci√≥n: Ayuda a verificar la
    homocedasticidad. Una dispersi√≥n uniforme de puntos sugiere varianza
    constante de los residuos. Si los puntos muestran un patr√≥n (por
    ejemplo, se ensanchan o estrechan a lo largo del eje de los
    ajustados), indica heterocedasticidad, lo que puede afectar la
    eficiencia de los estimadores.

4.  Residuos Estandarizados vs Apalancamiento (Residuals vs Leverage):

    ‚Ä¢ Qu√© muestra: Muestra los residuos estandarizados frente al
    apalancamiento de cada observaci√≥n, con curvas de distancia de Cook
    superpuestas. ‚Ä¢ Interpretaci√≥n: Identifica observaciones influyentes
    que tienen un gran impacto en el ajuste del modelo. Puntos con alto
    apalancamiento y residuos grandes pueden distorsionar los
    resultados. Las l√≠neas de distancia de Cook ayudan a detectar estos
    puntos. Observaciones m√°s all√° de estas l√≠neas merecen una revisi√≥n
    adicional.

Verifiquemos matem√°ticamente esto

```{r}
shapiro.test(mod3$residuals)
```

Parece que el modelo no mejora en la normalidad de residuos.

```{r}
library(stargazer)
stargazer(mod1,mod2,mod3) #de base, para LaTeX
```

```{r}
stargazer(mod1,mod2,mod3, type="text", title = "Resultados de regresi√≥n") #de base, para LaTeX
```

# Modelos lineales generalizados

Al trabajar con datos como los de Wooldridge de salarios, notamos que
hay unos problemas con las presunciones de cuadrados menores. Si bien
obtenemos resultados, estos pueden ser problem√°ticos al estar sesgados
por la falta de precisi√≥n en los modelos en relaci√≥n a los errores, que
no parecen estar bien distribuidos. Eso significa que las inferencias
podr√≠an no ser adecuadas.

Sabiendo que la regresi√≥n lineal predice directamente una respuesta
continua a partir del predictor lineal, $ùëãùõΩ$, un MLG o GLM extiende este
esquema de predicci√≥n lineal. Este consiste en:

```         
‚Ä¢   Un **predictor lineal** $ùëãùõΩ$.

‚Ä¢   Una **funci√≥n de enlace** $ùëî$, que es mon√≥tona y diferenciable en todo su dominio, y que transforma el predictor lineal: $ùë¶ÃÇ = ùëî‚Åª¬π(ùëãùõΩÃÇ$).

‚Ä¢   Una **distribuci√≥n de respuesta**: $ùëì(ùë¶\|ùúá)$ de la familia exponencial,
```

con valor esperado $ùúá = ùëî‚Åª¬π(ùëãùõΩ)$.

Esto proporciona flexibilidad para modelar diferentes tipos de variables
dependientes (respuestas), permitiendo que el modelo capture mejor las
caracter√≠sticas de los datos.

La funci√≥n `glm()` en R se utiliza para ajustar **Modelos Lineales
Generalizados (GLM en ingl√©s)**, que son una extensi√≥n de los modelos
lineales ordinarios (OLS). Estos modelos permiten manejar diferentes
tipos de variables de respuesta (dependientes), como binomiales,
Poisson, y gamma, entre otras. El modelo se define en funci√≥n de:

-   Una **funci√≥n de enlace** que describe la relaci√≥n entre las
    variables independientes y la media de la variable dependiente.

-   Una **distribuci√≥n** de la variable dependiente que puede no ser
    normal.

Los GLMs son √∫tiles cuando el rango de la variable de respuesta est√°
limitado y/o la varianza no es constante o normalmente distribuida. Los
modelos GLM transforman la variable de respuesta para permitir el ajuste
mediante m√≠nimos cuadrados. La transformaci√≥n aplicada a la variable de
respuesta est√° definida por la funci√≥n de enlace. Esta transformaci√≥n
puede restringir el rango de la variable de respuesta. La funci√≥n de
varianza especifica la relaci√≥n entre la varianza y la media. En R, una
familia especifica las funciones de varianza y enlace que se utilizan en
el ajuste del modelo. Por ejemplo, la familia ‚Äúpoisson‚Äù usa la funci√≥n
de enlace ‚Äúlog‚Äù y toma ‚Äú$Œº$‚Äù como la funci√≥n de varianza. Un modelo GLM
se define tanto por la f√≥rmula como por la familia.

Los modelos GLM tambi√©n pueden ajustarse a datos en los que la varianza
es proporcional a una de las funciones de varianza definidas. Esto se
hace con las familias cuasi, donde el œá¬≤ de Pearson (chi-cuadrado) se
utiliza para escalar la varianza. Un ejemplo ser√≠a cuando la varianza es
proporcional a la media. Esto usar√≠a la familia ‚Äúquasipoisson‚Äù. Esto
resulta en una funci√≥n de varianza de Œ±Œº en lugar de $1/Œº$ como en los
datos distribuidos seg√∫n Poisson. Las familias cuasi permiten hacer
inferencias cuando tus datos est√°n sobredispersos o subdispersos,
siempre que la varianza sea proporcional.

La funci√≥n de enlace predeterminada para una familia puede cambiarse
especificando un enlace a la funci√≥n de familia. Por ejemplo, si la
variable de respuesta es no negativa y la varianza es proporcional a la
media, se usar√≠a la funci√≥n de enlace ‚Äúidentity‚Äù con la familia
‚Äúquasipoisson‚Äù. Esto se especificar√≠a como:

``` r
family = quasipoisson(link = "identity")
```

La decisi√≥n sobre qu√© familia es apropiada no se discute en esta
secuencia, pero estos pueden ser:

``` r
binomial(link = "logit")
gaussian(link = "identity")
Gamma(link = "inverse")
inverse.gaussian(link = "1/mu^2")
poisson(link = "log")
quasi(link = "identity", variance = "constant")
quasibinomial(link = "logit")
quasipoisson(link = "log")
```

Revisar la p√°gina de ayuda de `glm` y la documentacion de objetos
familiares para modelos ayudar√° en gran medida.

**Sintaxis b√°sica de glm()**

``` r
glm(formula, family = family_type(link = link_function), data = dataset)
```

-   `formula`: Especifica la relaci√≥n entre las variables dependiente e
    independientes (similar a `lm()`).

-   `family`: Define la distribuci√≥n de la variable dependiente. Puede
    ser `gaussian` (para regresi√≥n lineal), `binomial` (para regresi√≥n
    log√≠stica), `poisson` (para modelos de conteo), `gamma`, entre
    otros.

-   `link`: Es la funci√≥n de enlace que conecta la media de la variable
    dependiente con las variables independientes (por ejemplo, `log`,
    `identity` o `inverse`).

```{r}
# Ajustando un modelo GLM con distribuci√≥n gamma y enlace logar√≠tmico
mod_glm <- glm(wage ~ educ + antig√ºedad + married, 
               family = Gamma(link = "log"), 
               data = base1)

# Resumen del modelo
summary(mod_glm)
```

```{r}
# Transformar wage a su logaritmo (eliminando ceros o valores negativos en wage)
base1 <- base1[base1$wage > 0, ]
base1$lwage <- log(base1$wage)

# Ajustando un modelo OLS con log(wage) como variable dependiente
mod_logwage <- lm(lwage ~ educ + antig√ºedad + married, data = base1)

# Resumen del modelo
summary(mod_logwage)
```

Notamos que la transformaci√≥n aproxima los coeficientes a los
conseguidos con el `glm()`.

```{r}
library(arm)
arm::coefplot(mod_glm, col.pts="red", cex.pts=1.5)
arm::coefplot(mod_logwage, add=TRUE, col.pts="blue", cex.pts=1.5)
```

## An√°lisis de la bondad del modelo

```{r}
plot(mod_glm)
```

Esto se ve posiblemente mejor que la variante de OLS, aunque tampoco
parece perfecto.

# Modelos jer√°rquicos

El paquete `lme4` est√° bien adaptado para los Modelos Jer√°rquicos
Lineales ‚Äúnormales‚Äù con grupos anidados. La sintaxis de `lme4` se basa
en la sintaxis de los modelos lineales que ya conocemos de `lm()`.

La funci√≥n `lmer()` de `lme4` a√±ade la especificaci√≥n de la variable de
grupo/sujeto y de la estructura de efectos aleatorios que se van a
estimar. En par√©ntesis adicionales (ver abajo), el t√©rmino a la
izquierda de `|` especifica los efectos aleatorios que se van a estimar.
El t√©rmino a la derecha de `|` representa la(s) variable(s) que definen
la estructura de agrupaci√≥n (o anidamiento) de los datos.

Un `1` en la parte izquierda del par√©ntesis significa que se debe
estimar un componente de varianza de intercepto aleatorio. Si tambi√©n se
coloca la variable predictora a la izquierda de `|`, esto indica que se
deben incluir pendientes aleatorias. La forma b√°sica de estos ser√°:

``` r
lmer(data = datos, VarDependiente ~ VarIndependiente + (1 | VarGrupal))
```

Corresponde a un modelo que puede describirse de la siguiente manera:
‚ÄúLa variable dependiente es predicha por la variable independiente. Al
mismo tiempo, la varianza de los residuos de nivel 2 del intercepto es
un par√°metro del modelo‚Äù.

Comencemos con modelos HLM que incluyen solo variables predictoras de
nivel 1 (individuos anidados en grupos). Luego, en un segundo paso,
a√±adiremos predictores de nivel 2. Finalmente, analizaremos los modelos
HLM de medidas repetidas, donde el nivel m√°s bajo (nivel 1) corresponde
a observaciones repetidas dentro de los individuos, y esas observaciones
est√°n anidadas en los participantes individuales (nivel 2).

Nos limitaremos aqu√≠ a modelos de 2 niveles. Los principios de los
modelos HLM pueden ilustrarse de manera bastante parsimoniosa de esta
forma, y expandir los modelos a m√°s de dos niveles de an√°lisis es
bastante sencillo.

```{r}
library(tidyverse)
df <- read_csv(
  url("https://raw.githubusercontent.com/methodenlehre/data/master/salary-data.csv"))
df <- df %>%
  mutate(firma = as.factor(firma),
         sector = as.factor(sector))
tail(df)
```

```{r}
library(Matrix)
library(lme4)
modelo.intercepto <- lmer(salary ~ 1 + (1 | firma), data = df, REML = TRUE)

# Aqu√≠, las predicciones del modelo corresponden al salario promedio de cada empresa.
# Almacenamos estos valores predichos (por persona/fila) para graficarlos m√°s tarde.
df$predicciones.intercepto <- predict(modelo.intercepto)

# Resultados del modelo
summary(modelo.intercepto)
```

Con la funci√≥n ranef() podemos ver los efectos aleatorios (residuos de segundo nivel del intercepto):

```{r}
ranef(modelo.intercepto)
```

Correlaci√≥n intraclase

La correlaci√≥n intraclase cuantifica el grado de ‚Äúno independencia‚Äù en la variable dependiente debido a diferencias sistem√°ticas de nivel 2 en la caracter√≠stica medida. Cuanto mayor sea la proporci√≥n de la varianza del nivel 2 (varianza de los promedios de grupo) con respecto a la varianza total (suma de la varianza del nivel 2 y la varianza del nivel 1 o varianza residual), mayores ser√°n las similitudes dentro de las unidades del nivel 2 en comparaci√≥n con las unidades entre niveles 2.

La correlaci√≥n intraclase se define como: 
$\rho = \frac{\sigma^2_{\text{Nivel-2}}}{\sigma^2_{\text{Nivel-2}} + \sigma^2_{\text{Nivel-1}}}$

La correlaci√≥n intraclase se obtiene estimando un modelo nulo (modelo solo con intercepto, ver arriba), en el cual tanto la varianza (aleatoria) del intercepto (en un modelo sin predictores, esto corresponde a la varianza de los promedios de grupo) como la varianza residual del nivel 1 son parte de la salida.

Correlaci√≥n intraclase: 
$\hat{\rho} = \frac{\hat{\sigma}^2_{œÖ_0}}{\hat{\sigma}^2_{œÖ_0} + \hat{\sigma}^2_{œµ}} = \frac{851249}{851249 + 1954745} = 0.3034$

Aproximadamente, el 30% de la varianza total del salario se puede atribuir a diferencias entre empresas.

Prueba de significancia para $\sigma^2_{œÖ_0}$: Comparaci√≥n del modelo con un ‚Äúmodelo nulo absoluto‚Äù (modelo solo con intercepto fijo $\gamma_{00}$).

Ya conocemos la varianza de nivel 2 de la variable dependiente salary, pero a√∫n no tenemos una prueba de significancia para este par√°metro. Podemos obtener una prueba de significancia comparando el modelo solo con intercepto con un modelo que no contiene interceptos aleatorios, es decir, con un ‚Äúmodelo lineal normal‚Äù sin un predictor (donde la media total $\gamma_{00}$ es el √∫nico par√°metro del modelo adem√°s de la varianza residual de nivel 1 $\sigma^2_{œµ}$). Este modelo tambi√©n se llama ‚Äúmodelo nulo absoluto‚Äù. No necesitamos especificar expl√≠citamente dicho modelo, ya que podemos aplicar la funci√≥n ranova() al objeto de salida intercept.only.model. La funci√≥n `ranova()` (del paquete auxiliar lmerTest para lme4) realiza autom√°ticamente comparaciones de modelos (solo) para efectos aleatorios eliminando paso a paso los efectos aleatorios existentes y luego comparando el modelo resultante con el modelo reducido. En este caso, solo se puede eliminar un efecto aleatorio, que es el del intercepto.

```{r}
library(lmerTest)
ranova(modelo.intercepto)
```
La comparaci√≥n de modelos es significativa (p < 0.001). Incluso podemos dividir el valor p por 2, ya que la comparaci√≥n corresponde en realidad a una prueba de una sola cola. El par√°metro $\sigma^2_{œÖ_0}$ tiene un espacio de par√°metros acotado (no puede ser negativo).

A√±adamos ahora un predictor de primer nivel como efecto fijo, con un intercepto aleatorio. Esto es √∫til para determinar la proporci√≥n de varianza explicada por un predictor de primer nivel.

```{r}
modelo.intercepto.aleatorio <-  lmer(salary ~ experience + (1 | firma), 
                                     data = df, REML = TRUE)

df$predicciones.intercepto.aleatorio <-  predict(modelo.intercepto.aleatorio)

summary(modelo.intercepto.aleatorio)
```
Los resultados del modelo mixto muestran que el efecto fijo de la experiencia es significativamente positivo, con un coeficiente estimado de  $\hat{\gamma}_{10} = 534.34$  y un valor $p$ menor a 0.001. Esto indica que, en promedio, el salario aumenta en aproximadamente 534 unidades (por ejemplo, francos suizos) por cada a√±o adicional de experiencia, controlando por las diferencias entre empresas. El modelo incluye un intercepto aleatorio a nivel de empresa (firma), lo que nos permite ajustar diferencias entre las empresas en los salarios base. 

Se le puede a√±adir un nivel adicional al modelo para tanto acomodar por un intercepto as√≠ como pendiente aleatoria. Al aplicar este modelo la varianza (aleatoria) de la pendiente de la variable independiente de primer nivel se puede estimar, d√°ndonos una idea de las diferencias en el efecto (pendiente) de experiencia en salario entre las unidades del segundo nivel (firmas)

```{r}
modelo.coeficientes.aleatorios <-  lmer(salary ~ experience + (experience | firma),
                                        data = df, REML = TRUE)

df$predicciones.coeficientes.aleatorios <-  predict(modelo.coeficientes.aleatorios)

summary(modelo.coeficientes.aleatorios)
```
Los resultados muestran que el efecto fijo de la experiencia sigue siendo significativamente positivo, con un coeficiente estimado de  $\hat{\gamma}_{10} = 530.85$  y un valor $p$ menor a 0.001. Esto indica que, en promedio, el salario aumenta en aproximadamente 531 unidades (por ejemplo, CHF para estos datos ficticios) por cada a√±o adicional de experiencia.

# Modelos longitudinales

La caracter√≠stica clave del an√°lisis de datos longitudinales es el
estudio de datos organizados con observaciones repetidas
tomadas de los mismos individuos. A menudo, el objetivo principal es
caracterizar el cambio en la respuesta a lo largo del tiempo (o
mediciones) y los factores que influyen en este cambio.

Las observaciones que pertenecen al mismo sujeto (o grupo/cluster)
tienden a ser m√°s similares que las observaciones de diferentes grupos.
Es importante tener en cuenta esta correlaci√≥n para obtener inferencias
v√°lidas.

Los datos longitudinales son un caso especial de datos jer√°rquicos,
donde las observaciones est√°n anidadas dentro de diferentes niveles
jer√°rquicamente ordenados, como mediciones dentro de individuos, o
alumnos dentro de escuelas (y dentro de regiones). Una vista general
sobre paquetes √∫tiles en R para analizar este tipo de datos
correlacionados se puede encontrar en la [CRAN Task View
dedicada](https://cran.r-project.org/web/views/MixedModels.html).

Usar√© los datos longitudinales de 27 ni√±os (16 ni√±os y 11 ni√±as) en el desarrollo de las distancias pituitarias-pterigomaxilares durante el crecimiento. Estas medidas se tomaron a las edades de 8, 10, 12 y 14 a√±os, con el objetivo de describir c√≥mo cambia esta distancia con la edad y comparar el patr√≥n de crecimiento entre ni√±os y ni√±as.

```{r}
load(url("http://alecri.github.io/downloads/data/dental.RData"))
head(dental)
```
Los datos se presentan en formato ancho, donde las mediciones repetidas se encuentran en columnas separadas para cada edad. Este formato no es ideal para el an√°lisis longitudinal, por lo que convertiremos los datos a un formato largo usando la funci√≥n pivot_longer():
```{r}
library(labelled)   # etiquetado de datos
library(rstatix)    # estad√≠sticas descriptivas
library(ggpubr)     # estad√≠sticas descriptivas y gr√°ficos convenientes
library(GGally)     # gr√°ficos avanzados
library(car)        # √∫til para ANOVA/pruebas de Wald
library(Epi)        # f√°cil obtenci√≥n de intervalos de confianza para coeficientes/predicciones del modelo
library(lme4)       # modelos lineales de efectos mixtos
library(lmerTest)   # pruebas para modelos lineales de efectos mixtos
library(emmeans)    # medias marginales
library(multcomp)   # intervalos de confianza para combinaciones lineales de coeficientes del modelo
library(geepack)    # ecuaciones de estimaci√≥n generalizadas
library(ggeffects)  # efectos marginales, predicciones ajustadas
library(gt)         # tablas bonitas
dental_long <- pivot_longer(dental, cols = starts_with("y"), 
                            names_to = "measurement", values_to = "distance") %>% 
  mutate(
    age = parse_number(measurement),
    measurement = fct_inorder(paste("Medida a los", age))
  ) %>% 
  set_variable_labels(
    age = "Edad del ni√±o/a al momento de la medici√≥n",
    measurement = "Etiqueta de medici√≥n temporal",
    distance = "Medici√≥n de distancia"
  )

head(dental_long)
```

Evaluando descriptivamente

```{r}
group_by(dental_long, age) %>% 
  get_summary_stats(distance)
```
Parece que el efecto aumenta con la edad. 

```{r}
ggplot(dental_long, aes(measurement, distance, fill = measurement)) +
  geom_boxplot() +
  geom_jitter(width = 0.2) +
  guides(fill = "none") +
  labs(x = "", y = "Crecimiento dental, mm")
```
Veamos si hay diferencias por sexo del paciente dental:
```{r}
group_by(dental_long, sex, measurement) %>% 
  get_summary_stats(distance, show = c("mean", "sd"))
```

Y gr√°ficamente

```{r}
ggplot(dental_long, aes(sex, distance, fill = measurement)) +
  geom_boxplot() +
  labs(x = "", y = "Crecimiento dental, mm", fill = "")
```
Evaluemos las correlaciones entre medidas de inter√©s:

```{r}
ggpairs(select(dental, starts_with("y")), lower = list(continuous = "smooth"))
```

y separemos nuevamente por grupo (sexo)

```{r}
ggpairs(dental, mapping = aes(colour = sex), columns = 3:6,
        lower = list(continuous = "smooth"))
```

Digamos que queremos entender si el efecto var√≠a con el tiempo. Podr√≠amos evaluar gr√°ficamente esto:

```{r}
group_by(dental_long, sex, age) %>% 
  summarise(mean = list(mean_ci(distance)), .groups = "drop") %>% 
  unnest_wider(mean) %>% 
  mutate(agex = age - .05 + .05*(sex == "Boy")) %>% 
  ggplot(aes(agex, y, col = sex, shape = sex)) +
  geom_point() +
  geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.2) +
  geom_line() +
  labs(x = "Edad, en a√±os", y = "Crecimiento dental medio, mm", shape = "Sex", col = "Sex")
```

 Una estrategia de modelado para investigar esto es utilizar variables indicadoras para contrastar las respuestas medias en diferentes momentos de la medici√≥n.
 
```{r}
lin_age <- lmer(distance ~ measurement + (1 | id), data = dental_long)
summary(lin_age)
```
 Resultados del modelo mixto lineal

Los resultados del modelo mixto muestran lo siguiente:

-	La distancia media dental a los 8 a√±os (valor de referencia) es 22.18 mm.
- La diferencia entre las respuestas medias de los ni√±os de 10 y 8 a√±os es de 0.98 mm.
- La diferencia entre las respuestas medias de los ni√±os de 12 y 8 a√±os es de 2.46 mm.
- La diferencia entre las respuestas medias de los ni√±os de 14 y 8 a√±os es de 3.91 mm.

Esto indica que la distancia pituitaria-pterigomaxilar aumenta significativamente con la edad, lo que es consistente con el crecimiento observado durante este per√≠odo.

Medias marginales y an√°lisis de varianza

La funci√≥n emmeans es √∫til para calcular medias marginales con sus correspondientes intervalos de confianza:
```{r}
tidy(emmeans(lin_age, "measurement"), conf.int = TRUE)
```

Prueba de significancia

Para probar si la respuesta media es constante a lo largo del tiempo, podemos realizar un An√°lisis de Varianza (ANOVA) para evaluar la hip√≥tesis nula de que todos los coeficientes de regresi√≥n utilizados para modelar el tiempo son simult√°neamente iguales a cero:

```{r}
Anova(lin_age)
```
Los resultados del test de Wald sugieren que la trayectoria de la respuesta media a lo largo del tiempo no es plana (p < 0.001), lo que significa que existe una variaci√≥n significativa en la respuesta media con la edad. Podemos presentar la trayectoria estimada del modelo ajustado utilizando la funci√≥n predict:

```{r}
# Generar predicciones del modelo ajustado
predicciones <- predict(lin_age)

# Visualizar la trayectoria estimada
ggplot(dental_long, aes(x = age, y = distance, color = sex)) +
  geom_point() +
  geom_line(aes(y = predicciones, group = id), linetype = "dashed") +
  labs(x = "Edad (a√±os)", y = "Distancia pituitaria-pterigomaxilar (mm)", color = "Sexo") +
  theme_minimal()
```
Este gr√°fico muestra tanto los datos reales de distancia en funci√≥n de la edad como las predicciones del modelo para cada ni√±o, con l√≠neas discontinuas que representan las trayectorias estimadas a lo largo del tiempo.
 
#  Qu√© aprendimos en este taller final

Aprendimos la existencia de varios modelos, maneras de representar gr√°ficamente sus resultados, y evaluar su utilidad.
